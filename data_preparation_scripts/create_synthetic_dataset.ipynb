{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a67b97",
   "metadata": {},
   "source": [
    "# Creation of the synthetic dataset\n",
    "\n",
    "Due to troubles with the dataset of original/highlighted simplified dataset, the decision was made to create a synthetic dataset to train the adapters.\n",
    "\n",
    "This notebook creates highlighted simplified texts from given original texts. You will get jsonl files that can directly be used to train and test the simplifier and highlighter of the Pipeline approach.\n",
    "The files for the end2end approach can be created with the notebook create_synthetic_dataset_end2end.ipynb.\n",
    "\n",
    "(You may find more details in the paper.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ef9d7b-2023-4d8d-bb34-d0c13cb91923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T17:04:46.296322Z",
     "iopub.status.busy": "2025-11-17T17:04:46.296027Z",
     "iopub.status.idle": "2025-11-17T17:05:03.399049Z",
     "shell.execute_reply": "2025-11-17T17:05:03.397978Z",
     "shell.execute_reply.started": "2025-11-17T17:04:46.296299Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "MODEL_NAME = \"google/gemma-2-9b-it\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# LOAD MODEL\n",
    "###############################################################################\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16 if DEVICE == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db1099-b6d5-432a-9c5b-01381a0b4cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:19:31.267503Z",
     "iopub.status.busy": "2025-11-18T18:19:31.266896Z",
     "iopub.status.idle": "2025-11-18T18:20:50.057333Z",
     "shell.execute_reply": "2025-11-18T18:20:50.055063Z",
     "shell.execute_reply.started": "2025-11-18T18:19:31.267451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cracle/data/conda/envs/training_gemma/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# -------------------------------\n",
    "# Model Configuration\n",
    "# -------------------------------\n",
    "MODEL_NAME = \"LeoLM/leo-mistral-hessianai-7b-chat\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------------------------------\n",
    "# Load Tokenizer\n",
    "# -------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# -------------------------------\n",
    "# Load Model\n",
    "# -------------------------------\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",  # Automatically place layers on available devices\n",
    "    torch_dtype=torch.bfloat16 if DEVICE == \"cuda\" else torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d11718-2614-44e2-9154-5dd7c541c07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:07:49.702461Z",
     "iopub.status.busy": "2025-11-18T17:07:49.701538Z",
     "iopub.status.idle": "2025-11-18T17:07:50.962305Z",
     "shell.execute_reply": "2025-11-18T17:07:50.961434Z",
     "shell.execute_reply.started": "2025-11-18T17:07:49.702421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie geht es dir? \n",
      " assistant\n",
      "Als KI habe ich keine Gefühle, daher ist es für mich nicht möglich, Emotionen zu erleben oder zu zeigen. Es geht mir einfach gut, danke für die Nachfrage. Wie geht es dir? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "inputs = tokenizer(\"Wie geht es dir?\", return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=2048,\n",
    "        temperature=0.1,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "raw = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898b70c",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "To create the synthetic dataset, the pipeline approach of first simplyfing (using Prompt1 and instruction_simplifier) and then highlighting (using Prompt2 and instruction_highlighter) was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ec7a1-76d1-40f3-9b3d-7a7076a7cf23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:33.119903Z",
     "iopub.status.busy": "2025-11-18T18:23:33.119259Z",
     "iopub.status.idle": "2025-11-18T18:23:33.125457Z",
     "shell.execute_reply": "2025-11-18T18:23:33.124234Z",
     "shell.execute_reply.started": "2025-11-18T18:23:33.119873Z"
    }
   },
   "outputs": [],
   "source": [
    "PROMPT1= \"\"\"<|im_start|>system\n",
    "Du bist ein hilfreicher Assistent, der Texte bereinigt und vereinfacht, wobei wichtige Wörter hervorgehoben werden.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Du erhältst einen Text.\n",
    "Deine Aufgabe: Erstelle ein Textpaar mit einer sauberen Version des Originaltextes und einer vereinfachten Version dieses Textes.\n",
    "\n",
    "Regeln:\n",
    "- Das Textpaar besteht aus (orig, simple)\n",
    "- Zuerst bereinige den Originaltext: Entferne alle Links, merkwürdige Formatierungen oder andere Artefakte aus der Vorverarbeitung. Es soll nur noch sauberer Text übrig bleiben, aber nichts umgeschrieben werden.\n",
    "- Nun erstelle aus diesem sauberen Text einen entsprechenden vereinfachten Text.\n",
    "- Der Text soll für Menschen mit kognitiven Beeinträchtigungen vereinfacht sein: Verwende sehr einfaches Vokabular, einfache Grammatik und wirklich sehr kurze Sätze.\n",
    "- Jeder Satz sollte in einer neuen Zeile stehen.\n",
    "\n",
    "\n",
    "WICHTIG:\n",
    "- Gib nur ein JSON-Array aus.\n",
    "- Format für das Textpaar genau wie folgt:\n",
    "\n",
    "[\n",
    "  {{\"orig\": sauberer Originaltext, \"simple\": vereinfachter Text}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "- Gib sonst nichts aus. Keine Erklärungen, keine Kommentare, kein zusätzlicher Text.\n",
    "- Verwende doppelte Anführungszeichen für alle Schlüssel und String-Werte.\n",
    "- Trenne mehrere Paare durch Kommata.\n",
    "\n",
    "Originaler Text:\n",
    "{orig}\n",
    "\n",
    "Textpaar:\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde7e50-bba2-4791-a78a-d3225261d17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:33.766950Z",
     "iopub.status.busy": "2025-11-18T18:23:33.766623Z",
     "iopub.status.idle": "2025-11-18T18:23:33.772477Z",
     "shell.execute_reply": "2025-11-18T18:23:33.770969Z",
     "shell.execute_reply.started": "2025-11-18T18:23:33.766923Z"
    }
   },
   "outputs": [],
   "source": [
    "instruction_simplifier = \"\"\"\n",
    "Du erhältst einen Text. Deine Aufgabe ist es, diesen Text zu bereinigen und zu vereinfachen.\n",
    "- Zuerst bereinige den Originaltext: Entferne alle Links, merkwürdige Formatierungen oder andere Artefakte aus der Vorverarbeitung. Es soll nur noch sauberer Text übrig bleiben, aber nichts umgeschrieben werden.\n",
    "- Nun erstelle aus diesem sauberen Text einen entsprechenden vereinfachten Text.\n",
    "- Der Text soll für Menschen mit kognitiven Beeinträchtigungen vereinfacht sein: Verwende sehr einfaches Vokabular, einfache Grammatik und wirklich sehr kurze Sätze.\n",
    "- Jeder Satz sollte in einer neuen Zeile stehen.\n",
    "- Gib sonst nichts aus. Keine Erklärungen, keine Kommentare, kein zusätzlicher Text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a42685-9369-430a-9aa6-5c4c644d81bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:34.290665Z",
     "iopub.status.busy": "2025-11-18T18:23:34.290183Z",
     "iopub.status.idle": "2025-11-18T18:23:34.295473Z",
     "shell.execute_reply": "2025-11-18T18:23:34.294590Z",
     "shell.execute_reply.started": "2025-11-18T18:23:34.290617Z"
    }
   },
   "outputs": [],
   "source": [
    "PROMPT2= \"\"\"<|im_start|>system\n",
    "Du bist ein hilfreicher Assistent, der Text in Markdown annotiert.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Du erhältst einen Text.\n",
    "Deine Aufgabe: Füge Markdown-Annotationen hinzu, ohne den Text inhaltlich zu verändern.  \n",
    "\n",
    "Anweisungen:\n",
    "- Annotiere Überschriften im Text mit Markdown (#, ## oder ###).\n",
    "- Markiere alle wichtigen Wörter oder Phrasen fett (**so**).\n",
    "- Halte dich strikt an das Markdown-Format.\n",
    "- WICHTIG: Ändere oder schreibe den Text nicht um! \n",
    "- Füge nur die Markdown-Annotationen hinzu.\n",
    "- Dein Output soll ausschließlich der originale Text mit den Markdown-Annotationen sein.\n",
    "- Gib keine Erklärungen, Kommentare oder zusätzlichen Text aus.\n",
    "\n",
    "Originaler Text:\n",
    "{simple}\n",
    "\n",
    "Textpaar:\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d06c0-1b12-42bc-8566-ee82d6b6366f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:34.930427Z",
     "iopub.status.busy": "2025-11-18T18:23:34.929814Z",
     "iopub.status.idle": "2025-11-18T18:23:34.935333Z",
     "shell.execute_reply": "2025-11-18T18:23:34.933857Z",
     "shell.execute_reply.started": "2025-11-18T18:23:34.930371Z"
    }
   },
   "outputs": [],
   "source": [
    "instruction_highlighter = \"\"\"\n",
    "Du erhältst einen Text. Deine Aufgabe ist es, Markdown-Annotationen hinzuzufügen, ohne den Text inhaltlich zu verändern.  \n",
    "- Annotiere Überschriften im Text mit Markdown (#, ## oder ###).\n",
    "- Markiere alle wichtigen Wörter oder Phrasen fett (**so**).\n",
    "- Halte dich strikt an das Markdown-Format.\n",
    "- WICHTIG: Ändere oder schreibe den Text nicht um! \n",
    "- Füge nur die Markdown-Annotationen hinzu.\n",
    "- Dein Output soll ausschließlich der originale Text mit den Markdown-Annotationen sein.\n",
    "- Gib keine Erklärungen, Kommentare oder zusätzlichen Text aus.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43700b8-8cf5-4db6-a3cb-d0ee592f55cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:38.232290Z",
     "iopub.status.busy": "2025-11-18T18:23:38.231533Z",
     "iopub.status.idle": "2025-11-18T18:23:38.239314Z",
     "shell.execute_reply": "2025-11-18T18:23:38.237775Z",
     "shell.execute_reply.started": "2025-11-18T18:23:38.232213Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import re\n",
    "import json\n",
    "\n",
    "def create_pair(orig_text):\n",
    "\n",
    "    try:\n",
    "        prompt = PROMPT1.replace(\"{orig}\", orig_text)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=4096,\n",
    "                temperature=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "\n",
    "        raw = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        #print(\"raw model output:\", raw)\n",
    "        parsed = extract_json_from_text(raw)\n",
    "        #print(\"json model output:\", parsed)\n",
    "        print(\"parsed\", type(parsed))\n",
    "\n",
    "        return parsed#json.dumps(parsed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error in pair:\", e)\n",
    "        traceback.print_exc()\n",
    "        return None   # Ensure failure never crashes main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0a1fd-d167-4ebc-a91f-f4896ca171f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:42.251343Z",
     "iopub.status.busy": "2025-11-18T18:23:42.251043Z",
     "iopub.status.idle": "2025-11-18T18:23:42.257316Z",
     "shell.execute_reply": "2025-11-18T18:23:42.255807Z",
     "shell.execute_reply.started": "2025-11-18T18:23:42.251319Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_json_list(json_list):\n",
    "    \"\"\"\n",
    "    Merge a list of dicts like:\n",
    "    [{'orig': '...', 'simple': '...'}, ...]\n",
    "    into a single dict:\n",
    "    {\"orig\": combined orig texts, \"simple\": combined simple texts}\n",
    "    \"\"\"\n",
    "    if not json_list:\n",
    "        return {\"orig\": \"\", \"simple\": \"\"}\n",
    "\n",
    "    entry_dict = {}\n",
    "    orig = \"\"\n",
    "    simple = \"\"\n",
    "    for d in json_list:\n",
    "        orig_text = d[\"orig\"]\n",
    "        simple_text = d[\"simple\"]\n",
    "        orig = orig + \"\\\\n\"+ orig_text\n",
    "        simple = simple + \"\\\\n\" + simple_text\n",
    "    entry_dict[\"orig\"] = orig\n",
    "    entry_dict[\"simple\"] = simple\n",
    "\n",
    "    return entry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2925e-0a62-43b6-83e9-e834989e6a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:47.168658Z",
     "iopub.status.busy": "2025-11-18T18:23:47.168273Z",
     "iopub.status.idle": "2025-11-18T18:23:47.178324Z",
     "shell.execute_reply": "2025-11-18T18:23:47.177028Z",
     "shell.execute_reply.started": "2025-11-18T18:23:47.168611Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Extracts the first JSON array from a text.\n",
    "    Handles:\n",
    "    - Whitespace/newlines\n",
    "    - Trailing commas\n",
    "    Returns a Python object (list/dict) if JSON is found, else None.\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return None\n",
    "\n",
    "    # Match everything between outer brackets\n",
    "    pattern = re.compile(r'assistant.*\\[\\s*(\\{.*\\})\\s*\\]', re.DOTALL)\n",
    "    match = pattern.search(text)\n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    output = match.group(0)\n",
    "\n",
    "    #print(\"FOUNDJSON\")\n",
    "    #print(json_str)\n",
    "        # Find the first '[' that starts the JSON array\n",
    "    start_idx = output.find('[')\n",
    "    if start_idx == -1:\n",
    "        return None  # No JSON array found\n",
    "\n",
    "    # Extract from the first '[' to the last ']' in the text\n",
    "    end_idx = output.rfind(']')\n",
    "    if end_idx == -1:\n",
    "        return None  # Malformed JSON\n",
    "\n",
    "    json_str = output[start_idx:end_idx+1]\n",
    "    json_str = json_str.replace(\"\\n\", \"\\\\n\")\n",
    "        # Detect if the string starts with '[\\n' literally and remove the '\\n'\n",
    "    # Only remove backslash-n that is **right after [ or { or ,**\n",
    "    json_str = re.sub(r'([\\[\\{\\,])\\\\n', r'\\1', json_str)\n",
    "    json_str = re.sub(r'([\\]\\}\\,])\\\\n', r'\\1', json_str)\n",
    "    json_str = json_str.replace(\"\\\"\\\\n\", \"\\\"\")\n",
    "    json_str = json_str.replace(\"{{\", \"{\")\n",
    "    json_str = json_str.replace(\"}}\", \"}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"json_str\", type(json_str))\n",
    "    #print(json_str)\n",
    "    try:\n",
    "        # Convert string to Python object safely\n",
    "        data = ast.literal_eval(json_str)\n",
    "        if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
    "            fixed_json = data\n",
    "        else:\n",
    "            raise ValueError(\"The input string does not represent a list of dictionaries.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Could not parse the string: {e}\")\n",
    "        \n",
    "    parsed = merge_json_list(fixed_json)\n",
    "\n",
    "    print(\"merged\", type(parsed))\n",
    "    \n",
    "\n",
    "    try:\n",
    "        return parsed\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse JSON: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536cf6e-f1c7-41b5-afa4-4cfbad2b835e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:50.795334Z",
     "iopub.status.busy": "2025-11-18T18:23:50.794630Z",
     "iopub.status.idle": "2025-11-18T18:23:50.802004Z",
     "shell.execute_reply": "2025-11-18T18:23:50.800553Z",
     "shell.execute_reply.started": "2025-11-18T18:23:50.795259Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight(text):\n",
    "    try:\n",
    "        prompt = PROMPT2.replace(\"{simple}\", text)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=4096,\n",
    "                temperature=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "\n",
    "        raw = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        #print(\"raw model output:\", type(raw))\n",
    "        return raw\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error in highlight:\", e)\n",
    "        traceback.print_exc()\n",
    "        return None   # Ensure failure never crashes main loop    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64229a93-c915-4c2a-90c9-af77989f7cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:52.202671Z",
     "iopub.status.busy": "2025-11-18T18:23:52.202306Z",
     "iopub.status.idle": "2025-11-18T18:23:52.213485Z",
     "shell.execute_reply": "2025-11-18T18:23:52.211574Z",
     "shell.execute_reply.started": "2025-11-18T18:23:52.202641Z"
    }
   },
   "outputs": [],
   "source": [
    "def simplify(INPUT_FILE, SIMPLE_OUTPUT_FILE):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf8\") as f:\n",
    "        lines = [json.loads(l) for l in f]\n",
    "\n",
    "    out = open(SIMPLE_OUTPUT_FILE, \"w\", encoding=\"utf8\")\n",
    "\n",
    "    failed_org_simple = []\n",
    "\n",
    "    for entry in tqdm(lines):\n",
    "        orig = entry[\"input\"]\n",
    "\n",
    "        pair = create_pair(orig)\n",
    "\n",
    "        if pair == None:\n",
    "            failed_org_simple.append(entry[\"id\"])\n",
    "            print(\"failed:\", entry[\"id\"])\n",
    "            continue\n",
    "\n",
    "        new_entry = {\n",
    "                \"id\": entry.get(\"id\"),\n",
    "                \"instruction\": instruction_simplifier,#entry.get(\"instruction\", \"\"),\n",
    "                \"input\": pair[\"orig\"].strip(),\n",
    "                \"output\": pair[\"simple\"].strip(),\n",
    "                \"metadata\": entry.get(\"metadata\", {})\n",
    "            }\n",
    "        out.write(json.dumps(new_entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    out.close()\n",
    "\n",
    "    print(\"These org_simple lines failed:\")\n",
    "    print(failed_org_simple)\n",
    "    print(\"Done! Saved:\", SIMPLE_OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d5255-5028-4185-af1f-fbc46ec9f3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:23:53.885475Z",
     "iopub.status.busy": "2025-11-18T18:23:53.884936Z",
     "iopub.status.idle": "2025-11-18T18:23:53.894581Z",
     "shell.execute_reply": "2025-11-18T18:23:53.892884Z",
     "shell.execute_reply.started": "2025-11-18T18:23:53.885444Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_entries(SIMPLE_OUTPUT_FILE, MARKED_OUTPUT_FILE):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with open(SIMPLE_OUTPUT_FILE, \"r\", encoding=\"utf8\") as f2:\n",
    "        lines2 = [json.loads(l) for l in f2]\n",
    "\n",
    "    print(lines2[0])\n",
    "    out2 = open(MARKED_OUTPUT_FILE, \"w\", encoding=\"utf8\")\n",
    "\n",
    "    failed_highlight = []\n",
    "    \n",
    "    for entry2 in tqdm(lines2):\n",
    "        simple = entry2[\"output\"]\n",
    "        highlighted = highlight(simple)\n",
    "        start_idx = highlighted.find('assistant')\n",
    "        if start_idx == -1:\n",
    "            highlighted_simple = None  # or handle error\n",
    "        else:\n",
    "            # Take everything from 'assistant' until the end\n",
    "            highlighted_simple = highlighted[start_idx + len('assistant'):].lstrip()\n",
    "            highlighted_simple = highlighted_simple.replace(\"```markdown\", \"\") #\n",
    "            highlighted_simple = highlighted_simple.replace(\"Originaler Text:\", \"\") \n",
    "            highlighted_simple = highlighted_simple.replace(\"```\", \"\") \n",
    "\n",
    "\n",
    "\n",
    "        if highlighted_simple == None:\n",
    "            failed_highlight.append(entry2[\"id\"])\n",
    "            print(\"failed:\", entry2[\"id\"])\n",
    "            continue\n",
    "        new_entry = {\n",
    "            \"id\": entry2.get(\"id\"),\n",
    "            \"instruction\": instruction_highlighter,#entry2.get(\"instruction\", \"\"),\n",
    "            \"input\": entry2[\"output\"].strip(),\n",
    "            \"output\": highlighted_simple,\n",
    "            \"metadata\": entry2.get(\"metadata\", {})\n",
    "        }\n",
    "        out2.write(json.dumps(new_entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    out2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37e889",
   "metadata": {},
   "source": [
    "If you the model skipped some lines in the first your run, you can can create files for a redo of just those failed ones with the following codeblock and rerun the model in the codeblock after this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1d6a2-c098-46e4-8319-11983cdbe987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:24:54.301286Z",
     "iopub.status.busy": "2025-11-18T18:24:54.300766Z",
     "iopub.status.idle": "2025-11-18T18:24:54.400998Z",
     "shell.execute_reply": "2025-11-18T18:24:54.399581Z",
     "shell.execute_reply.started": "2025-11-18T18:24:54.301261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entries in a 39\n",
      "entries skipped in b 17\n",
      "Total lines in part 2: 17\n"
     ]
    }
   ],
   "source": [
    "# create new files with the entries that were missed in the last round\n",
    "INPUT_FILE = \"data/Accessibility_Seminar/datasets_for_models/simplifier_test.jsonl\"         # Your original dataset\n",
    "\n",
    "def load_ids(path):\n",
    "    ids = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                if \"id\" in obj:\n",
    "                    ids.add(str(obj[\"id\"]))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Could not parse line in {path}\")\n",
    "    return ids\n",
    "\n",
    "    \n",
    "ids_a = load_ids(\"data/Accessibility_Seminar/datasets_for_models/simplifier_test.jsonl\") # the original texts\n",
    "ids_b = load_ids(\"data/Accessibility_Seminar/datasets_for_models_synthetic/simplifier_test.jsonl\") # the entries in the synthetic set\n",
    "\n",
    "only_in_a = sorted(ids_a - ids_b)\n",
    "print(\"entries in a\", len(ids_a))\n",
    "print(\"entries skipped in b\", len(only_in_a))\n",
    "\n",
    "INPUT_FILE_part2 = \"data/Accessibility_Seminar/datasets_for_models/simplifier_test_part2.jsonl\"         # Your original dataset\n",
    "SIMPLE_OUTPUT_FILE_part2 = \"data/Accessibility_Seminar/datasets_for_models_synthetic/simplifier_test_part2.jsonl\"   \n",
    "MARKED_OUTPUT_FILE_part2 = \"data/Accessibility_Seminar/datasets_for_models_synthetic/highlighter_test_part2.jsonl\" \n",
    "\n",
    "# Write matching full records from A into output file\n",
    "total_lines = 0\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f_in, \\\n",
    "    open(INPUT_FILE_part2, \"w\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "    for line in f_in:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        if str(obj.get(\"id\")) in only_in_a:\n",
    "            total_lines+=1\n",
    "            f_out.write(json.dumps(obj, ensure_ascii=False) +\"\\n\")\n",
    "print(f\"Total lines in part 2: {total_lines}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503a69f-26bc-475b-beeb-fad47093e822",
   "metadata": {},
   "source": [
    "in val:\n",
    "\n",
    "\n",
    "These org_simple lines failed:\n",
    "['5456', '3536', '3429', '3245', '3963', '4018', '3230', '3309', '3458', '3420', '5446', '37', '3249', '3973', '3538', '5780', '5782', '3438']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d13c3-a2da-47f7-980e-73f8f5222dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T18:26:53.340513Z",
     "iopub.status.busy": "2025-11-18T18:26:53.340215Z",
     "iopub.status.idle": "2025-11-18T18:32:17.803389Z",
     "shell.execute_reply": "2025-11-18T18:32:17.802425Z",
     "shell.execute_reply.started": "2025-11-18T18:26:53.340490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 1/17 [00:07<02:02,  7.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 5788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [00:12<01:31,  6.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3/17 [00:19<01:28,  6.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_str <class 'str'>\n",
      "merged <class 'dict'>\n",
      "parsed <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4/17 [00:29<01:42,  7.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_str <class 'str'>\n",
      "merged <class 'dict'>\n",
      "parsed <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [00:45<02:11, 10.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [00:54<01:50, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [01:05<01:44, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_str <class 'str'>\n",
      "merged <class 'dict'>\n",
      "parsed <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (32768). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      " 47%|████▋     | 8/17 [01:58<03:37, 24.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [02:15<02:53, 21.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 3433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [02:16<01:47, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/sctmp/cracle/ipykernel_3987211/2477413509.py\", line 51, in extract_json_from_text\n",
      "    data = ast.literal_eval(json_str)\n",
      "  File \"/home/cracle/data/conda/envs/training_gemma/lib/python3.10/ast.py\", line 64, in literal_eval\n",
      "    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
      "  File \"/home/cracle/data/conda/envs/training_gemma/lib/python3.10/ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "  File \"<unknown>\", line 1\n",
      "    [ {   \"orig\": \"Selbst­be­stimm­tes Le­ben\\n\\nIn der Konvention werden die Freiheits- und Schutzrechte ergänzt um eine Gruppe von Rechte, die Menschen ein selbstbestimmtes Leben ermöglichen sollen. Dazu gehört insbesondere das Recht auf Anerkennung vor dem Recht (Artikel 12), auf Unabhängige Lebensführung (Artikel 19), auf persönliche Mobilität (Artikel 20), auf die Achtung der Privatsphäre (Artikel 22) und auf die Achtung vor Heim und Familie (Artikel 23).\\nEine Grundlage für ein selbstbestimmtes Leben für Menschen mit Behinderungen ist die gleiche Anerkennung vor dem Recht (Artikel 12). Nur dadurch, dass die Entscheidung von Menschen auch eine rechtliche Bedeutung hat, kann die Selbstbestimmung in einer Gesellschaft, die sich über das Recht organisiert, überhaupt effektiv sein. Die Formulierung von Artikel 12 war in dem Ad-hoc Ausschuss zur Erarbeitung der Konvention umstritten, dort wurde teilweise eine Beschränkung der Anerkennung auf bestimmte Lebensbereiche gefordert. Dieser Vorschlag für eine Beschränkung hat sich nicht durchsetzen können, so dass die Konvention die Rechts- und Handlungsfähigkeit in allen Lebensbereichen vorsieht. Einige Staaten haben daher einen sogenannten Vorbehalt zu Artikel 12 hinterlegt, da sie fürchteten, dass ihre nationalen Regelungen zur Geschäftsfähigkeit möglicherweise nicht in Einklang mit Artikel 12 gebracht werden könnten. Deutschland hat auf einen solchen Vorbehalt verzichtet.\\nDa Menschen mit Behinderungen in der Vergangenheit als \\\"Objekte\\\" der Fürsorge angesehen wurden, drückt sich in diesem Artikel deutlich der Wandel hin zu einem menschenrechtsorientierten Ansatz im Umgang mit Menschen mit Behinderungen aus. Behinderte Menschen sind als \\\"Rechtssubjekte\\\" zu behandeln. Zur Verwirklichung dieses Rechtes, welches aus Artikel 6 der Allgemeinen Erklärung der Menschenrechte und aus Artikel 16 des Paktes über bürgerliche und politische Rechte stammt, sind die Staaten gefordert, den Zugang zu Unterstützung bei der Ausübung der Rechts- und Handlungsfähigkeit zu organisieren. Ebenfalls sind wirksame Missbrauchssicherungen zu schaffen, damit diese Unterstützung für Menschen mit Behinderungen nicht ausgenutzt oder gegen den Willen der betroffenen Personen missbraucht werden kann. Zudem ist zu gewährleisten, dass zunächst immer der Wille und die Präferenz der Person beachtet wird und nur Maßnahmen möglich sind, die auf die individuellen Umstände der Person zugeschnitten sind und nicht länger als notwendig andauern. In Deutschland ergibt sich daraus für das Betreuungsrecht, dass die Betreuung zurückhaltend ausgeübt werden muss und die Betreuerin oder der Betreuer in jedem Fall den Willen der betreuten Person in Erfahrung bringen muss.\\nIm Hinblick auf das Ziel, die Sicherung eines selbstbestimmten Lebens zu erreichen, sind auch die Bestimmungen über die unabhängige Lebensführung und die Einbeziehung in die Gemeinschaft (Artikel 19) zu betrachten. Danach ist für Menschen mit Behinderungen das Recht zu gewährleisten, über ihren Aufenthaltsort, ihre Mitbewohner und die Wohnform selbst zu entscheiden. \\n\\n\\n}, {   \"simple\": \\n\\n\\n    Artikel 1 - Recht auf Anerkennung vor dem Gesetz\\nArtikel 2 - Recht auf Unabhängige Lebensführung\\nArtikel 3 - Recht auf persönliche Mobilität\\nArtikel 4 - Recht auf die Achtung der Privatsphäre\\nArtikel 5 - Recht auf die Achtung vor Heim und Familie\\nArtikel 6 - Recht auf Bildung\\nArtikel 7 - Recht auf Arbeit und Beschäftigung\\nArtikel 8 - Recht auf einen angemessenen Lebensstandard und ausreichenden Lebensunterhalt\\nArtikel 9 - Recht auf soziale Sicherheit\\nArtikel 10 - Recht auf Gesundheit und Gesundheitsdienste\\nArtikel 11 - Recht auf Teilhabe an politischer und öffentlicher Sphäre\\nArtikel 12 - Recht auf rechtliche Handlungsfähigkeit\\nArtikel 13 - Recht auf Zugang zu Justiz\\nArtikel 14 - Recht auf Meinungs-, Gedanken-, Gewissens- und Religionsfreiheit sowie Informationsfreiheit\\nArtikel 15 - Recht auf Anrufung bei einer internationalen Beschwerdeinstanz\\nArtikel 16 - Verbot der Diskriminierung\\nArtikel 17 - Verbot der Ausgrenzung\\nArtikel 18 - Verbot der Misshandlung und gewaltsamen Behandlung\\nArtikel 19 - Recht auf unabhängige Lebensführung und Einbeziehung in die Gemeinschaft\\nArtikel 20 - Recht auf persönliche Mobilität\\nArtikel 21 - Recht auf Informationen\\nArtikel 22 - Recht der Privatsphäre\\nArtikel 23 - Achtung der Wohnung und der Familie\\n\\n\\n}]\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^\n",
      "SyntaxError: unterminated string literal (detected at line 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/sctmp/cracle/ipykernel_3987211/1235673801.py\", line 25, in create_pair\n",
      "    parsed = extract_json_from_text(raw)\n",
      "  File \"/sctmp/cracle/ipykernel_3987211/2477413509.py\", line 60, in extract_json_from_text\n",
      "    raise ValueError(f\"Could not parse the string: {e}\")\n",
      "ValueError: Could not parse the string: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
      " 65%|██████▍   | 11/17 [02:35<01:39, 16.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_str <class 'str'>\n",
      "Error in pair: Could not parse the string: unterminated string literal (detected at line 1) (<unknown>, line 1)\n",
      "failed: 3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [02:55<01:28, 17.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_str <class 'str'>\n",
      "merged <class 'dict'>\n",
      "parsed <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 13/17 [02:57<00:51, 12.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14/17 [03:11<00:39, 13.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [03:30<00:29, 14.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [04:12<00:23, 23.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_str <class 'str'>\n",
      "merged <class 'dict'>\n",
      "parsed <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [04:52<00:00, 17.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed <class 'NoneType'>\n",
      "failed: 5478\n",
      "These org_simple lines failed:\n",
      "['5788', '3530', '3436', '3306', '26', '3433', '3998', '3253', '13', '5462', '29', '5478']\n",
      "Done! Saved: data/Accessibility_Seminar/datasets_for_models_synthetic/simplifier_test_part2.jsonl\n",
      "{'id': '5476', 'instruction': '\\nDu erhältst einen Text. Deine Aufgabe ist es, diesen Text zu bereinigen und zu vereinfachen.\\n- Zuerst bereinige den Originaltext: Entferne alle Links, merkwürdige Formatierungen oder andere Artefakte aus der Vorverarbeitung. Es soll nur noch sauberer Text übrig bleiben, aber nichts umgeschrieben werden.\\n- Nun erstelle aus diesem sauberen Text einen entsprechenden vereinfachten Text.\\n- Der Text soll für Menschen mit kognitiven Beeinträchtigungen vereinfacht sein: Verwende sehr einfaches Vokabular, einfache Grammatik und wirklich sehr kurze Sätze.\\n- Jeder Satz sollte in einer neuen Zeile stehen.\\n- Gib sonst nichts aus. Keine Erklärungen, keine Kommentare, kein zusätzlicher Text.\\n', 'input': '\\\\nLinks und Veranstaltungen\\\\nWahl-Informationen vom Innen-Ministerium findest du HIER.\\\\nEs gibt viel Information in leichter Sprache. Klicke zuerst auf ein Thema. Und dann auf das Feld \"Leichter Lesen\".\\\\nDu kannst dich dort über die Wahl am 15. Oktober 2017, Wahlen generell, die Brief-Wahl, Vorzugs-Stimmen und andere Themen informieren. Dort steht zum Beispiel auch, was du tun musst, wenn du im Ausland lebst.\\\\nDie Stadt Wien hat Informationen zum Wählen für Menschen mit Behinderungen geschrieben. Achtung, die Sprache ist nicht einfach! Aber dort stehen sehr wichtige Informationen.\\\\nDie Lebenshilfe Österreich untersucht die Wahl-Programme der Parteien. Sie schauen, was sie zu Inklustion und Teilhabe machen wollen. Am 28. September werden die Ergebnisse präsentiert. Mehr Informationen findest du HIER.', 'output': '\\\\nInformationen über Wahlen\\\\nDu findest Informationen über Wahlen unter diesem Link.\\\\nSchau dir die einfache Version der Informationen an.\\\\nDu kannst über Wahlen und wie du abstimmst lesen.\\\\nDie Stadt Wien hat Informationen über das Wählen für Menschen mit Behinderungen. Aber die Sprache ist schwer zu verstehen. Es gibt jedoch wichtige Informationen.\\\\nEine andere Gruppe schaut sich die Wahl-Programme an. Sie möchten wissen, ob die Parteien für alle Menschen gleich sind.', 'metadata': {'source_file': '5476_LS.html', 'base_href': '', 'html_title': 'rechtleicht.at |   Links und Veranstaltungen', 'meta_title': ''}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 1/5 [00:01<00:07,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "\\nInformationen über Wahlen\\nDu findest Informationen über Wahlen unter diesem Link.\\nSchau dir die einfache Version der Informationen an.\\nDu kannst über Wahlen und wie du abstimmst lesen.\\nDie Stadt Wien hat Informationen über das Wählen für Menschen mit Behinderungen. Aber die Sprache ist schwer zu verstehen. Es gibt jedoch wichtige Informationen.\\nEine andere Gruppe schaut sich die Wahl-Programme an. Sie möchten wissen, ob die Parteien für alle Menschen gleich sind.\n",
      "OUTPUT\n",
      "\n",
      "Informationen über Wahlen\n",
      "Du findest Informationen über Wahlen unter diesem Link.\n",
      "Schau dir die einfache Version der Informationen an.\n",
      "Du kannst über Wahlen und wie du abstimmst lesen.\n",
      "Die Stadt Wien hat Informationen über das Wählen für Menschen mit Behinderungen. Aber die Sprache ist schwer zu verstehen. Es gibt jedoch wichtige Informationen.\n",
      "Eine andere Gruppe schaut sich die Wahl-Programme an. Sie möchten wissen, ob die Parteien für alle Menschen gleich sind.\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:07<00:11,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "\\nDas Allge­mei­ne Gleichbehandlungs­gesetz (AGG)\n",
      "Das AGG trat am 18. August 2006 in Kraft. Mit diesem Gesetz ist der Gesetzgeber einer sehr wichtigen Forderung von Menschen mit Behinderungen nachgekommen: einen besseren Schutz vor Benachteiligungen auch im privaten Rechtsverkehr zu schaffen.\n",
      "I. Das arbeitsrechtliche Benachteiligungsverbot im AGG\n",
      "    1. Wer wird geschützt?\n",
      "    2. Wer wird verpflichtet?\n",
      "    3. Welche Rechte stehen zu?\n",
      "\n",
      "II. Das zivilrechtliche Benachteiligungsverbot\n",
      "    1. Wann gilt im Zivilrecht das Benachteiligungsverbot?\n",
      "    2. Wann ist eine Ungleichbehandlung zulässig?\n",
      "    3. Welche Ansprüche haben Betroffene im Fall eines Verstoßes?\n",
      "\n",
      "III. Antidiskriminierungsstelle\n",
      "    a. Wer wird geschützt?\n",
      "    b. Wer wird verpflichtet?\n",
      "    c. Welche Rechte stehen zu?\n",
      "\n",
      "IV. Fachtag '10 Jahre Allgemeines Gleichbehandlungsgesetz'.\\nDokumentation '10 Jahre AGG'\n",
      "Dokumentation '10 Jahre AGG' in Leichter Sprache.\n",
      "OUTPUT\n",
      "\n",
      "Das Allge­mei­ne Gleichbehandlungs­gesetz (AGG)\n",
      "Das AGG trat am 18. August 2006 in Kraft. Mit diesem Gesetz ist der Gesetzgeber einer sehr wichtigen Forderung von Menschen mit Behinderungen nachgekommen: einen besseren Schutz vor Benachteiligungen auch im privaten Rechtsverkehr zu schaffen.\n",
      "\n",
      "I. Das arbeitsrechtliche Benachteiligungsverbot im AGG\n",
      "    1. **Wer wird geschützt?**\n",
      "    2. **Wer wird verpflichtet?**\n",
      "    3. **Welche Rechte stehen zu?**\n",
      "\n",
      "II. Das zivilrechtliche Benachteiligungsverbot\n",
      "    1. Wann gilt im Zivilrecht das Benachteiligungsverbot?\n",
      "    2. Wann ist eine Ungleichbehandlung zulässig?\n",
      "    3. **Welche Ansprüche haben Betroffene im Fall eines Verstoßes?**\n",
      "\n",
      "III. Antidiskriminierungsstelle\n",
      "    a. **Wer wird geschützt?**\n",
      "    b. **Wer wird verpflichtet?**\n",
      "    c. **Welche Rechte stehen zu?**\n",
      "\n",
      "IV. Fachtag '10 Jahre Allgemeines Gleichbehandlungsgesetz'.\n",
      "    - **Wer wird geschützt?**\n",
      "    - **Wer wird verpflichtet?**\n",
      "    - **Welche Rechte stehen zu?**\n",
      "\n",
      "Textpaar:\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:13<00:09,  4.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "\\nAllgemeine Verpflichtungen\n",
      "In Artikel 4 der Behindertenrechtskonvention sind die \"Allgemeinen Verpflichtungen\" des Staates aufgeführt. Es sind dort verschiedene Punkte benannt, die der Vertragsstaat erfüllen muss. Eine grundlegende Verpflichtung besteht darin, \"Disability Mainstreaming\" einzuführen, was bedeutet, dass der Schutz und die Förderung der Rechte von Menschen mit Behinderungen bei allen politischen Konzepten und Programmen zu berücksichtigen ist. Die Staaten haben aber auch die Verpflichtung, Gesetze und Verordnungen anzupassen und das \n",
      "konventionsgemäße Handeln\n",
      " durch alle öffentlichen Aufgabenträger (Behörden, Sozialversicherungen) sicherzustellen. Im Bereich der \n",
      "Forschung und Entwicklung\n",
      " für Güter, Dienstleistungen, Geräte und Einrichtungen in universellem Design und als unterstützende Technologien hat der Staat dafür zu sorgen, dass diese Forschung stattfindet und dass die Informationen über solche Produkte auch den Menschen zur Verfügung stehen. Ebenfalls hat der Staat dafür zu sorgen, dass \n",
      "Schulungen\n",
      " über die Inhalte der Konvention für Fachkräfte stattfinden. Eine weitere grundlegende Verpflichtung ist, dass bei der Ausarbeitung und Umsetzung von Rechtsvorschriften und politischen Konzepten \n",
      "Organisationen von Menschen mit Behinderungen\n",
      " aktiv durch die Regierung beteiligt werden.\n",
      "OUTPUT\n",
      "# Allgemeine Verpflichtungen\n",
      "\n",
      "- In Artikel 4 der Behindertenrechtskonvention sind die \"Allgemeinen Verpflichtungen\" des Staates aufgeführt.\n",
      "- Es sind dort verschiedene Punkte benannt, die der Vertragsstaat erfüllen muss.\n",
      "- Eine grundlegende Verpflichtung besteht darin, \"Disability Mainstreaming\" einzuführen, was bedeutet, dass der Schutz und die Förderung der Rechte von Menschen mit Behinderungen bei allen politischen Konzepten und Programmen zu berücksichtigen ist.\n",
      "- Die Staaten haben aber auch die Verpflichtung, Gesetze und Verordnungen anzupassen und sicherzustellen, dass das \n",
      "- konventionsgemäße Handeln durch alle öffentlichen Aufgabenträger (Behörden, Sozialversicherungen) erfolgt.\n",
      "- Im Bereich der \n",
      "- Forschung und Entwicklung für Güter, Dienstleistungen, Geräte und Einrichtungen in universellem Design und als unterstützende Technologien hat der Staat dafür zu sorgen, dass diese Forschung stattfindet und dass die Informationen über solche Produkte auch den Menschen zur Verfügung stehen.\n",
      "- Ebenfalls hat der Staat dafür zu sorgen, dass \n",
      "- Schulungen über die Inhalte der Konvention für Fachkräfte stattfinden.\n",
      "- Eine weitere grundlegende Verpflichtung ist, dass bei der Ausarbeitung und Umsetzung von Rechtsvorschriften und politischen Konzepten \n",
      "- Organisationen von Menschen mit Behinderungen aktiv durch die Regierung beteiligt werden. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:22<00:06,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "\\ntaz leicht sagt erstmal \"Tschüss\"\n",
      "Es war ein spannendes Jahr für taz leicht.\n",
      "Im Sommer 2017 begannen wir mit etwas so noch nicht Dagewesenem in den deutschen Medien: Wir übersetzten zur Bundestagswahl meinungsstarke taz-Texte in Leichte Sprache, um auch jene LeserInnen zu erreichen, für die das \"Standardprogramm\" unserer Zeitung zu schwer zu lesen ist.\n",
      "Seither haben wir über 70 taz-Texte in kurze Sätze übersetzt und damit Leichter Sprache und ihren LeserInnen zu mehr Sichtbarkeit verholfen.\n",
      "Sie brauchen taz leicht nicht allein zu lesen! Wir haben viele Rückmeldungen von ganz unterschiedlichen LeserInnen bekommen – von Menschen mit Lernschwierigkeiten, Angehörigen, persönlichen Assistenzen, Förderschulen, Bibliotheken, SprachlehrerInnen, anderen Leichte-Sprache-Projekten, HelferInnen in der Flüchtlingshilfe, Menschen, die gerade Deutsch lernen und Eltern, die die Texte ihren Kindern zu lesen geben.\n",
      "Dieselbe Zeitung lesen, die auch alle anderen lesen\n",
      "Eine Frau schrieb uns – ihr Mann sei früher taz-Abonnent gewesen. Nach einem Schlaganfall konnte er die Zeitung aber nicht mehr lesen. Mit taz leicht konnten sie das wieder gemeinsam tun.\n",
      "Wir freuen uns, dass dieses Projekt ein Jahr lang in dieser Form möglich war. Für die Finanzierung von regelmäßigen Beiträgen fehlen leider die Mittel. Um sich nicht ganz verabschieden zu müssen, soll das Projekt allerdings zu besonderen Anlässen, zu Sonderprojekten, weitergeführt werden. Es gibt also hoffentlich schon bald ein Wiedersehen. Über Twitter und Facebook geben wir bekannt, wenn es soweit ist.\n",
      "Wir danken allen, die uns unterstützt haben. Besonderer Dank geht an die taz, die taz Panter Stiftung, die Fürst Donnersmarck Stiftung und an die PrüferInnen vom Leichte-Sprache-Büro \"Capito\", die all unsere Texte noch besser gemacht haben!  \n",
      "Von CHRISTINE STÖCKEL, JULIANE FIEGLER und BELINDA GRASNICK von taz leicht\n",
      "OUTPUT\n",
      "# Annotierter Text #\n",
      "- Annotiere die Überschrift mit Markdown (#).\n",
      "\n",
      "**Taz leicht sagt erstmal \"Tschüss\"**\n",
      "Es war ein spannendes Jahr für taz leicht.\n",
      "\n",
      "Im Sommer 2017 begannen wir mit etwas so noch nicht Dagewesenem in den deutschen Medien: Wir übersetzten zur Bundestagswahl meinungsstarke taz-Texte in Leichte Sprache, um auch jene LeserInnen zu erreichen, für die das \"Standardprogramm\" unserer Zeitung zu schwer zu lesen ist.\n",
      "Seither haben wir über 70 taz-Texte in kurze Sätze übersetzt und damit Leichter Sprache und ihren LeserInnen zu mehr Sichtbarkeit verholfen.\n",
      "\n",
      "Sie brauchen taz leicht nicht allein zu lesen! Wir haben viele Rückmeldungen von ganz unterschiedlichen LeserInnen bekommen – von Menschen mit Lernschwierigkeiten, Angehörigen, persönlichen Assistenzen, Förderschulen, Bibliotheken, SprachlehrerInnen, anderen Leichte-Sprache-Projekten, HelferInnen in der Flüchtlingshilfe, Menschen, die gerade Deutsch lernen und Eltern, die die Texte ihren Kindern zu lesen geben.\n",
      "\n",
      "Dieselbe Zeitung lesen, die auch alle anderen lesen\n",
      "\n",
      "Eine Frau schrieb uns – ihr Mann sei früher taz-Abonnent gewesen. Nach einem Schlaganfall konnte er die Zeitung aber nicht mehr lesen. Mit taz leicht konnten sie das wieder gemeinsam tun.\n",
      "\n",
      "Wir freuen uns, dass dieses Projekt ein Jahr lang in dieser Form möglich war. Für die Finanzierung von regelmäßigen Beiträgen fehlen leider die Mittel. Um sich nicht ganz verabschieden zu müssen, soll das Projekt allerdings zu besonderen Anlässen, zu Sonderprojekten, weitergeführt werden. Es gibt also hoffentlich schon bald ein Wiedersehen. Über Twitter und Facebook geben wir bekannt, wenn es soweit ist.\n",
      "\n",
      "Wir danken allen, die uns unterstützt haben. Besonderer Dank geht an die taz, die taz Panter Stiftung, die Fürst Donnersmarck Stiftung und an die PrüferInnen vom Leichte-Sprache-Büro \"Capito\", die all unsere Texte noch besser gemacht haben! \n",
      "\n",
      "Von CHRISTINE STÖCKEL, JULIANE FIEGLER und BELINDA GRASNICK von taz leicht. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "\\nWir stellen Ihnen unsere Partner vor.\\nDas ist eine Liste unserer Partner. Wir arbeiten mit ihnen zusammen, um Ihnen eine bessere Erfahrung zu bieten.\\nWir stellen Ihnen 1a Zugang vor.\\nWir bieten Beratung für Unternehmen und Institutionen an.\\n1a Zugang hilft Menschen mit Behinderungen, damit sie einen einfachen Zugang zu Dingen haben.\\n1a Zugang arbeitet mit Unternehmen zusammen, um Dinge leicht zugänglich zu machen.\\nSie können mehr über 1a Zugang auf ihrer Website erfahren.\\nWir stellen Ihnen capito Stuttgart vor.\\ncapito Stuttgart hilft Menschen, Texte leicht zu lesen und zu verstehen.\\ncapito macht Texte einfach zu lesen.\\ncapito arbeitet mit Übersetzungen, um Texte einfach zu machen.\\nSie können capito Stuttgart unter dieser Adresse finden.\\nWir stellen Ihnen Femos gGmbH vor.\\nFemos ist eine gemeinnützige Organisation. Sie hilft Menschen und macht dabei keine Gewinne.\\nFemos wird von Wilhelm Kohlberger geleitet.\\nSie können Femos unter dieser Adresse finden.\\nWir stellen Ihnen INNONET Kunststoff vor.\\nINNONET Kunststoff hilft Unternehmen, die Kunststoff verwenden.\\nINNONET Kunststoff hilft Menschen, Arbeit zu finden, indem sie Kontakte knüpfen und Ausbildung anbieten.\\nSie können mehr über INNONET Kunststoff auf ihrer Website erfahren.\\nWir stellen Ihnen LGI Logistics Group International GmbH vor.\\nLGI Logistics hilft Menschen, Dinge zu transportieren.\\nLGI Logistics bietet Menschen Praktika und Möglichkeiten zur Qualifizierung an.\\nLGI Logistics hilft Menschen, Arbeit zu finden und Dinge zu transportieren.\\nWir stellen Ihnen Müller – Die lila Logistik vor.\\nMüller - Die lila Logistik bietet Menschen Praktika und Arbeitsplätze an.\\nMüller - Die lila Logistik und die GWW arbeiten zusammen, um Menschen bei der Arbeit und beim Transport von Dingen zu helfen.\\nMüller - Die lila Logistik und die GWW arbeiten zusammen, um Dinge zu transportieren und Montage- oder Konfektionierungsarbeiten durchzuführen.\\nMüller - Die lila Logistik und die GWW bieten gemeinsam Lösungen für Kunden an.\\nWir stellen Ihnen Stiftung Zenit vor.\\nStiftung Zenit hilft Menschen, Arbeit zu finden und in die Gemeinschaft zu gehören.\n",
      "OUTPUT\n",
      "Wir stellen Ihnen unsere Partner vor.\\nDas ist eine Liste unserer Partner. Wir arbeiten mit ihnen zusammen, um Ihnen eine bessere Erfahrung zu bieten.\\nWir stellen Ihnen 1a Zugang vor.\\nWir bieten Beratung für Unternehmen und Institutionen an.\\n1a Zugang hilft Menschen mit Behinderungen, damit sie einen einfachen Zugang zu Dingen haben.\\n1a Zugang arbeitet mit Unternehmen zusammen, um Dinge leicht zugänglich zu machen.\\nSie können mehr über 1a Zugang auf ihrer Website erfahren.\\nWir stellen Ihnen capito Stuttgart vor.\\ncapito Stuttgart hilft Menschen, Texte leicht zu lesen und zu verstehen.\\ncapito macht Texte einfach zu lesen.\\ncapito arbeitet mit Übersetzungen zusammen, um Texte einfach zu machen.\\nSie können capito Stuttgart unter dieser Adresse finden.\\nWir stellen Ihnen Femos gGmbH vor.\\nFemos ist eine gemeinnützige Organisation. Sie hilft Menschen und macht dabei keine Gewinne.\\nFemos wird von Wilhelm Kohlberger geleitet.\\nSie können Femos unter dieser Adresse finden.\\nWir stellen Ihnen INNONET Kunststoff vor.\\nINNONET Kunststoff hilft Unternehmen, die Kunststoff verwenden.\\nINNONET Kunststoff hilft Menschen, Arbeit zu finden, indem sie Kontakte knüpfen und Ausbildung anbieten.\\nSie können mehr über INNONET Kunststoff auf ihrer Website erfahren.\\nWir stellen Ihnen LGI Logistics Group International GmbH vor.\\nLGI Logistics hilft Menschen, Dinge zu transportieren.\\nLGI Logistics bietet Menschen Praktika und Möglichkeiten zur Qualifizierung an.\\nLGI Logistics hilft Menschen, Arbeit zu finden und Dinge zu transportieren.\\nWir stellen Ihnen Müller – Die lila Logistik vor.\\nMüller - Die lila Logistik bietet Menschen Praktika und Arbeitsplätze an.\\nMüller - Die lila Logistik und die GWW arbeiten zusammen, um Menschen bei der Arbeit und beim Transport von Dingen zu helfen.\\nMüller - Die lila Logistik und die GWW arbeiten zusammen, um Dinge zu transportieren und Montage- oder Konfektionierungsarbeiten durchzuführen.\\nMüller - Die lila Logistik und die GWW bieten gemeinsam Lösungen für Kunden an.\\nWir stellen Ihnen Stiftung Zenit vor.\\nStiftung Zenit hilft Menschen, Arbeit zu finden und in die Gemeinschaft zu gehören. \n",
      "\n",
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# MAIN PROCESSING LOOP\n",
    "###############################################################################\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "INPUT_FILE = \"data/Accessibility_Seminar/datasets_for_models/simplifier_test_part2.jsonl\"         # Your original dataset\n",
    "SIMPLE_OUTPUT_FILE = \"data/Accessibility_Seminar/datasets_for_models_synthetic/simplifier_test_part2.jsonl\"   # Cleaned and aligned pairs\n",
    "MARKED_OUTPUT_FILE = \"data/Accessibility_Seminar/datasets_for_models_synthetic/highlighter_test_part2.jsonl\" \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    simplify(INPUT_FILE, SIMPLE_OUTPUT_FILE)\n",
    "    highlight_entries(SIMPLE_OUTPUT_FILE, MARKED_OUTPUT_FILE)\n",
    "\n",
    "    print(\"DONE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d673aad-ce43-4247-bd22-25777b3a4634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2709ec-590c-4b2f-aaaf-9f31ab964727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
